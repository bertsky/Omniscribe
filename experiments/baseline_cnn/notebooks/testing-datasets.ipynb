{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports 1 complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "print(\"imports 1 complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded from C:\\Users\\rahul\\Documents\\work\\BuildUCLA\\data\\printed_with_ids\\images\n",
      "read classes: ['negative', 'positive']\n",
      "use_gpu is true\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\rahul\\\\Documents\\\\work\\\\BuildUCLA\\\\data\\\\printed_with_ids\\\\images\"\n",
    "\n",
    "set_types = ['train', 'val', 'test']\n",
    "\n",
    "# Need to split data sets into training and testing sets\n",
    "data_sets = {t : datasets.ImageFolder(data_dir, transform=data_transforms[t])\n",
    "             for t in set_types}\n",
    "\n",
    "# Need to split data into training set, validation set, and testing set\n",
    "train_size = 0.65     # 65% of all data is training\n",
    "val_size = 0.15       # 15% of all data is validation\n",
    "test_size = (1 - train_size - val_size)    # Remaining data (20%) is testing\n",
    "\n",
    "num_images = len(data_sets[\"train\"]) # length of both sets should be the same\n",
    "all_ind = list(range(num_images))\n",
    "random_seed = 11\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(all_ind)\n",
    "\n",
    "train_split = int(num_images * train_size)\n",
    "val_split = int(num_images * val_size)\n",
    "test_split = int(num_images * test_size)\n",
    "\n",
    "data_samplers = {}\n",
    "data_samplers[\"train\"] = all_ind[:train_split]\n",
    "data_samplers[\"val\"] = all_ind[train_split : train_split+val_split]\n",
    "data_samplers[\"test\"] = all_ind[train_split+val_split:]\n",
    "\n",
    "dataloaders = {t : torch.utils.data.DataLoader(data_sets[t],\n",
    "                                              sampler=data_samplers[t],\n",
    "                                              batch_size=4,\n",
    "                                              num_workers=4)\n",
    "              for t in set_types}\n",
    "\n",
    "dataset_sizes = {t : len(data_samplers[t]) for t in set_types}\n",
    "\n",
    "class_names = data_sets[\"train\"].classes\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(\"data loaded from \" + str(data_dir))\n",
    "print(\"read classes: \" + str(class_names))\n",
    "if use_gpu:\n",
    "    print(\"use_gpu is true\")\n",
    "else:\n",
    "    print(\"use_gpu is false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_type = train\n",
      "total = 1832\n",
      "pos = 1290\n",
      "pos ratio = 0.7041484716157205\n",
      "\n",
      "set_type = val\n",
      "total = 422\n",
      "pos = 299\n",
      "pos ratio = 0.7085308056872038\n",
      "\n",
      "set_type = test\n",
      "total = 565\n",
      "pos = 389\n",
      "pos ratio = 0.6884955752212389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for set_type in set_types:\n",
    "    poscount = 0\n",
    "    totcount = 0\n",
    "    for inputs, labels in dataloaders[set_type]:\n",
    "        for label in labels:\n",
    "            totcount = (totcount + 1)\n",
    "            if label == 1:\n",
    "                poscount = (poscount + 1)\n",
    "    print(\"set_type = \" + str(set_type))\n",
    "    print(\"total = \" + str(totcount))\n",
    "    print(\"pos = \" + str(poscount))\n",
    "    print(\"pos ratio = \" + str(float(poscount)/float(totcount)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(weights_path):\n",
    "    model_resnet18 = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model_resnet18.fc.in_features\n",
    "    model_resnet18.fc = nn.Linear(num_ftrs, 2)\n",
    "    print(\"acquired resnet18 architecture\")\n",
    "\n",
    "    # weights_path = \"resnet18_half_frozen_5epochs_transfer-state.pt\"\n",
    "    model_resnet18.load_state_dict(torch.load(weights_path))\n",
    "    model_resnet18.cuda()\n",
    "    print(\"loaded weights from \" + weights_path)\n",
    "    \n",
    "    return model_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to evaluate model\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_1epochs_transfer-state.pt\n",
      "Epoch 1\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[112  64]\n",
      " [ 65 324]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_2epochs_transfer-state.pt\n",
      "Epoch 2\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[141  35]\n",
      " [100 289]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_3epochs_transfer-state.pt\n",
      "Epoch 3\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[114  62]\n",
      " [ 55 334]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_4epochs_transfer-state.pt\n",
      "Epoch 4\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[130  46]\n",
      " [ 57 332]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_5epochs_transfer-state.pt\n",
      "Epoch 5\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[120  56]\n",
      " [ 43 346]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_6epochs_transfer-state.pt\n",
      "Epoch 6\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[139  37]\n",
      " [ 57 332]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_7epochs_transfer-state.pt\n",
      "Epoch 7\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[150  26]\n",
      " [ 70 319]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_8epochs_transfer-state.pt\n",
      "Epoch 8\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[136  40]\n",
      " [ 48 341]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_9epochs_transfer-state.pt\n",
      "Epoch 9\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[136  40]\n",
      " [ 50 339]]\n",
      "\n",
      "acquired resnet18 architecture\n",
      "loaded weights from resnet18_half_frozen_10epochs_transfer-state.pt\n",
      "Epoch 10\n",
      "printing confusion matrix of format:\n",
      "[[TN FP]\n",
      " [FN TP]]\n",
      "[[137  39]\n",
      " [ 54 335]]\n",
      "\n",
      "evaluation complete\n"
     ]
    }
   ],
   "source": [
    "print(\"try to evaluate model\")\n",
    "\n",
    "import torchnet as tnt\n",
    "\n",
    "for epoch in range(10):\n",
    "    model_resnet18 = load_model(\"resnet18_half_frozen_\" + str(epoch + 1) + \"epochs_transfer-state.pt\")\n",
    "    model_resnet18.eval()\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(2)\n",
    "\n",
    "    for i, data in enumerate(dataloaders[\"test\"]):\n",
    "        input, label = data\n",
    "        input_var = Variable(input, volatile=True).cuda()\n",
    "        label_var = Variable(label, volatile=True).cuda()\n",
    "        score = model_resnet18(input_var)\n",
    "        confusion_matrix.add(score.data,\n",
    "                             label_var.data)\n",
    "\n",
    "    print(\"Epoch \" + str(epoch + 1))\n",
    "    print(\"printing confusion matrix of format:\")\n",
    "    print(\"[[TN FP]\\n [FN TP]]\")\n",
    "    print(confusion_matrix.conf)\n",
    "    print()\n",
    "print(\"evaluation complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
