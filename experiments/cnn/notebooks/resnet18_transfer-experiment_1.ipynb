{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 1 with resnet18 transfer learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "import torchnet as tnt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "print(\"imports 1 complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including different forms of data augmentation\n",
    "# One will include nearly all types (excluding random crops, etc. that may remove handwriting.)\n",
    "# The other will include a selected set of augmentations\n",
    "\n",
    "# Keeping 'train', 'val', and 'test' transforms just in case we want to include different functionalities\n",
    "\n",
    "all_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(90),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        \n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(90),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        \n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(90),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        \n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "selected_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        \n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        \n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        \n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Set up data transforms.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data configuration, like data directory and transforms\n",
    "\n",
    "# data_dir = \"C:\\\\Users\\\\rahul\\\\Documents\\\\work\\\\BuildUCLA\\\\data\\\\printed_with_ids\\\\images\"\n",
    "data_dir = \"C:\\\\Users\\\\rahul\\\\Documents\\\\work\\\\BuildUCLA\\\\data\\\\printed_with_ids_harsh_filter\\\\preprocessed-images\"\n",
    "meta_data_loc = \"C:\\\\Users\\\\rahul\\\\Documents\\\\work\\\\BuildUCLA\\\\data\\\\printed_with_ids_harsh_filter\\\\book_number_mapping.csv\"\n",
    "\n",
    "print(data_dir)\n",
    "print(meta_data_loc)\n",
    "\n",
    "data_transforms = selected_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read meta data of the images, and make book-index mapping dictionary\n",
    "\n",
    "# Assumes meta data file:\n",
    "#   - has field names in first row\n",
    "#   - the field names are in this order: [\"id\", \"book\", \"label\"]\n",
    "\n",
    "# Create a dict of dicts:\n",
    "#   - keys are based on the value in \"label\"\n",
    "#   - values are the \"inner\" dicts described below\n",
    "# Each \"inner\" dict has:\n",
    "#   - keys are the book names, specified in \"book\"\n",
    "#   - each value is a list of all the indices denoted by \"id\"\n",
    "book_mapping = {}\n",
    "\n",
    "with open(meta_data_loc, mode='r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for row in reader:\n",
    "        if row[\"label\"] not in book_mapping:\n",
    "            book_mapping[row[\"label\"]] = {}\n",
    "        bm = book_mapping[row[\"label\"]]\n",
    "        \n",
    "        if row[\"book\"] not in bm:\n",
    "            bm[row[\"book\"]] = []\n",
    "        bm[row[\"book\"]].append(row[\"id\"])\n",
    "\n",
    "count = 0\n",
    "for l in book_mapping:\n",
    "    for b in book_mapping[l]:\n",
    "        count += len(book_mapping[l][b])\n",
    "\n",
    "print(\"read meta data for \" + str(count) + \" images from \" + str(meta_data_loc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "set_types = ['train', 'val', 'test']\n",
    "\n",
    "# Need to split data sets into training and testing sets\n",
    "data_sets = {t : datasets.ImageFolder(data_dir, transform=data_transforms[t])\n",
    "             for t in set_types}\n",
    "\n",
    "# Need to split data into training set, validation set, and testing set\n",
    "train_size = 0.65     # 65% of all data is training\n",
    "val_size = 0.15       # 15% of all data is validation\n",
    "test_size = (1 - train_size - val_size)    # Remaining data (20%) is testing\n",
    "\n",
    "num_images = len(data_sets[\"train\"]) # length of both sets should be the same\n",
    "all_ind = list(range(num_images))\n",
    "random_seed = 11\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(all_ind)\n",
    "\n",
    "train_split = int(num_images * train_size)\n",
    "val_split = int(num_images * val_size)\n",
    "test_split = int(num_images * test_size)\n",
    "\n",
    "data_samplers = {}\n",
    "data_samplers[\"train\"] = all_ind[:train_split]\n",
    "data_samplers[\"val\"] = all_ind[train_split : train_split+val_split]\n",
    "data_samplers[\"test\"] = all_ind[train_split+val_split:]\n",
    "\n",
    "dataloaders = {t : torch.utils.data.DataLoader(data_sets[t],\n",
    "                                              sampler=data_samplers[t],\n",
    "                                              batch_size=4,\n",
    "                                              num_workers=4)\n",
    "              for t in set_types}\n",
    "\n",
    "dataset_sizes = {t : len(data_samplers[t]) for t in set_types}\n",
    "\n",
    "class_names = data_sets[\"train\"].classes\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(\"data loaded from \" + str(data_dir))\n",
    "print(\"read classes: \" + str(class_names))\n",
    "if use_gpu:\n",
    "    print(\"use_gpu is true\")\n",
    "else:\n",
    "    print(\"use_gpu is false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "print(\"visualized a few images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a class to deal with early stopping criteria\n",
    "# Important: minimizes a loss value\n",
    "class EarlyStopping:\n",
    "    def __init__(self, min_delta=0, patience=5):\n",
    "        # The minimum delta in loss to be considered a change in loss\n",
    "        self.min_delta = min_delta\n",
    "        \n",
    "        # number of epochs to wait for improvement before terminating\n",
    "        self.patience = patience\n",
    "        \n",
    "        # number of epochs waited\n",
    "        self.wait = 0\n",
    "        \n",
    "        # Set \"best loss\" to some large number\n",
    "        self.best_loss = 1e15\n",
    "        \n",
    "    def checkStoppingCriteria(self, curr_loss):\n",
    "        \"\"\" Returns whether the stopping criteria has been met. \"\"\"\n",
    "        if (curr_loss - self.best_loss) < -self.min_delta:\n",
    "            self.best_loss = curr_loss\n",
    "            self.wait = 1\n",
    "        elif self.wait < self.patience:\n",
    "            self.wait += 1\n",
    "        else:\n",
    "            return True\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"This 'train_model' function is a generic routine that can be used to train various models.\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, earlyStopping = None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    val_acc_loss = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Confusion matrix\n",
    "            confusion_matrix = tnt.meter.ConfusionMeter(2)\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Add to confusion matrix\n",
    "                confusion_matrix.add(outputs.data, labels.data)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            # save each epoch's model\n",
    "#             weights_path = \"resnet18_half_frozen_\" + str(epoch + 1) + \"epochs_transfer-state.pt\"\n",
    "#             torch.save(model_resnet18.state_dict(), weights_path)\n",
    "#             print(\"saved epoch \" + str(epoch + 1) + \" model state (weights) to \" + weights_path)\n",
    "#             print(\"ran epoch \" + str(epoch + 1))\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Print confusion matrix\n",
    "            print(confusion_matrix.conf)\n",
    "            print()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            # store most recent val_loss\n",
    "            if phase == 'val':\n",
    "                val_acc_loss = (1.0 - epoch_acc)\n",
    "                print(\"val_acc_loss = \" + str(val_acc_loss))\n",
    "        \n",
    "        \n",
    "        # Extra spacing\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "        # Include early stopping criteria check at end of epoch\n",
    "        if (earlyStopping is not None) and earlyStopping.checkStoppingCriteria(val_acc_loss):\n",
    "            print(\"Stopping after epoch \" + str(epoch) + \" due to early stopping criteria.\")\n",
    "            break\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Transferring resnet18 and retraining with annotations dataset.\")\n",
    "\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "num_params = sum(1 for i in model_resnet18.parameters())\n",
    "\n",
    "# There are 10 layers (model_ft.children()) in resnet18\n",
    "# Freezing the first half of resnet18, freezing all params for layers 1-5\n",
    "max_layer = 5\n",
    "curr_layer = 1\n",
    "last_layer = None\n",
    "for child in model_resnet18.children():\n",
    "    if curr_layer <= max_layer:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        last_layer = child\n",
    "        curr_layer = curr_layer + 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# for child in model.children():\n",
    "#     print(\"\")\n",
    "#     print(child)\n",
    "        \n",
    "# Replace the final fully connected layer to perform binary classification\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "if use_gpu:\n",
    "    model_resnet18 = model_resnet18.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Need to create slightly custom optimizer since half of the layers are frozen\n",
    "optimizer = optim.SGD(list(filter(lambda p: p.requires_grad, model_resnet18.parameters())), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Create LR scheduler that decays LR by a factor of 0.1 for every 7 epochs (this is from tutorial, might need tweaking)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "print(\"Created new model to train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"perform training\")\n",
    "num_training_epochs = 50\n",
    "earlyStoppingCriteria = EarlyStopping(min_delta = 1e-4, patience=5)\n",
    "\n",
    "model_resnet18 = train_model(model_resnet18,\n",
    "                             criterion,\n",
    "                             optimizer,\n",
    "                             exp_lr_scheduler,\n",
    "                             num_epochs=num_training_epochs,\n",
    "                             earlyStopping = earlyStoppingCriteria)\n",
    "\n",
    "print(\"training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = \"resnet18_half_frozen_5epochs_transfer-state.pt\"\n",
    "torch.save(model_resnet18.state_dict(), weights_path)\n",
    "print(\"saved model state (weights) to \" + weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, data in enumerate(dataloaders['test']):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "            imshow(inputs.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                model.train(mode=was_training)\n",
    "                return\n",
    "    model.train(mode=was_training)\n",
    "\n",
    "visualize_model(model_resnet18)\n",
    "print(\"visualizing model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"running on testing dataset\")\n",
    "model_resnet18.train(False)  # Set model to evaluate mode\n",
    "\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Iterate over data.\n",
    "for data in dataloaders[\"test\"]:\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "\n",
    "    # wrap them in Variable\n",
    "    if use_gpu:\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "    # forward\n",
    "    outputs = model_resnet18(inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # backward + optimize only if in training phase\n",
    "#     if phase == 'train':\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "    # statistics\n",
    "    running_loss += loss.data[0] * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "epoch_loss = running_loss / dataset_sizes[\"test\"]\n",
    "epoch_acc = running_corrects / dataset_sizes[\"test\"]\n",
    "\n",
    "print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "    \"test\", epoch_loss, epoch_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
