{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1 with resnet18 transfer learning\n",
    "============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import gc\n",
    "import torchnet as tnt\n",
    "from utils import *\n",
    "from classes import *\n",
    "from tqdm import tqdm_notebook # for-loop progress bar in notebook\n",
    "\n",
    "# plt setup and the gpu setup\n",
    "plt.ion()\n",
    "use_gpu = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data transforms.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Step 1. define data transform\n",
    "#\n",
    "# Including different forms of data augmentation\n",
    "# One will include nearly all types (excluding random crops, etc. that may remove handwriting.)\n",
    "# The other will include a selected set of augmentations\n",
    "# Keeping 'train', 'val', and 'test' transforms just in case we want to include different functionalities\n",
    "# ========================================\n",
    "\n",
    "print(\"Set up data transforms.\")\n",
    "img_input_size = 56\n",
    "\n",
    "selected_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        \n",
    "        transforms.Grayscale(), # not sure why the current input is not grayscale, do grayscale conversion\n",
    "        transforms.Resize((img_input_size,img_input_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    # should not do random transformation in val or test set\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((img_input_size,img_input_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((img_input_size,img_input_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "data_transforms = selected_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dataset and dataloader\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Step 2. define and load data\n",
    "#\n",
    "# TODO: Suggest not using data loader to load the images. Because it is slow. Every epochs, you load the \n",
    "# image data again to the RAM and then from RAM to GPU RAM. That takes a lot of time. Since the images are \n",
    "# <1GB, you can preload the images into RAM first, that will make you training way faster. \n",
    "\n",
    "# Note: you only has about 200MB of images, it's small. It should not take much time to load!\n",
    "# ========================================\n",
    "print(\"Create dataset and dataloader\")\n",
    "\n",
    "# hyperparameter\n",
    "batch_size = 50 # larger batch size is better so you can load more data into gpu and train faster\n",
    "\n",
    "# data location\n",
    "book_data_dir = \"/home/kcho/clab_data/\"\n",
    "set_types = ['train', 'val', 'test']\n",
    "\n",
    "# test books are currently arbitrarily set\n",
    "test_books = set([\"Albin\", \"Dryden\"])\n",
    "\n",
    "# Get the list of all books in the data set\n",
    "books_in_data = set([b for b in os.listdir(book_data_dir)\n",
    "                 if os.path.isdir(os.path.join(book_data_dir, b))])\n",
    "\n",
    "# Create a dict of datasets for each book\n",
    "book_data_sets = {b : {t : datasets.ImageFolder(os.path.join(book_data_dir, b), \n",
    "                                                transform = data_transforms[t])#, transform=test_transform)\n",
    "                      for t in set_types}\n",
    "                 for b in books_in_data}\n",
    "\n",
    "# create a dict of dataloaders, book_data_loaders['Albin']['train']\n",
    "book_data_loaders = {b : {t : torch.utils.data.DataLoader(book_data_sets[b][t],\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          shuffle=True, # make sure you shuffle the data\n",
    "                                                          num_workers=4)\n",
    "                          for t in set_types}\n",
    "                     for b in books_in_data}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 56, 56)\n",
      "(56, 56)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnV2sndV55/9PDAQCCebT3/gjNgYTgkkckopcUDKpPJmquYmiptWICyRuOlKqtmqglUbtaEZKbpr2YlTJUiK46JSkaisQqqZlPKBRpYbYjPmwMfYxYINt7EMSO3FIQjj2mou9fWat3zlnr73Px97bWf+fZJ397Hfv913vevfyu/7P86znjZSSjDFt8YFRN8AYM3w88I1pEA98YxrEA9+YBvHAN6ZBPPCNaRAPfGMaxAPfmAZZ0MCPiJ0RcSgijkTEw4vVKGPM0hLzzdyLiGWSDkv6vKTjkvZI+kpK6ZUe33Ga4DyIiMJetmxZYV9++eWFffXVV0+//tCHPlRsu/LKK3t+9wMfKO8Fl112Wc/trTLouOE1HIR33323sCcmJgr7/PnzhZ1Sqh7sstoHenCPpCMppdclKSIel/RFSXMOfNMf/JF88IMfLOxrr722sFesWFHYn/70p6df79ixo9i2ZcuWnt/9yEc+Utg33HBDYV911VWFfeHChcL+Vf2PgYNrlsFW2LX/rGn34nvf+15h79y5s7B//OMf972viyzkKq2R9FZmH+++VxARD0XE3ojYu4BjGWMWkYXc8fsipbRL0i7JU31jxoWFDPwTktZl9true83BaR119Ic//OHC5nR67dq1hb1x48bC3rRpU2Fzun777bcX9tatW6dfU6Nzas7tpKZNx2lqz+k27Xx6zunx9ddfX9gnT54s7Lfeequwcz+KNLMfTp06Vdi33XZbYfOa9+Kaa64pbEq/+bCQq7ZH0paI2BgRV0j6bUlPLrhFxpglZ953/JTSVET8J0n/LGmZpG+nlA4sWsuMMUvGgjR+SumfJP3TIrXFGDMklty5N65Qk11xxRWFzZDZypUrC/vmm2+efk299olPfKKwP/rRjxY2dTO/f+ONNxY2fQIMqQ0SIx4kjLTY1GLfv/zlLwub5zU1NVXY7733XmH/4he/KGyG3PLPT05OFts+9alPFfbPf/7zwqYPYM2aMoD13HPPFTbzJ9jWQaA/gdd/PoyPZ8YYMzQ88I1pEA98YxrkktL4uT5lrHz58uWFvW7dusJetWpVYTNV9ZZbbinsPBYuzdTpeY47892Z5kqNRn/CQvK4hw119s9+9rPC5rnluv7YsWPFNsajqYNrcXkem/kS1Pg//elPp1/zPPhZ+kKYL3/06NHC5u8nP5Y002cwCIzj0/80H3zHN6ZBPPCNaRAPfGMaZKgaf9myZUVMmrHODRs2FDZz1j/2sY9Nv6ZuZpyVOpvHuummmwqbPgLuj9p1nHn//fenXzM3nzqZurrmb/jhD39Y2MePHy9s5iDksXXG2anxqdHZ5/w+czHo9yE/+MEPpl+zX2gzp+BHP/pRYXONA31C9BHQHzEIjNvztzoffMc3pkE88I1pkKFO9bds2aJHH3102uZSxzvuuKOwOR3Pp/cMx3AKy2nkOIfQ8qm5NDO0xHNlqIhTwXxKe/r06WIbp6D8LkNH586dK2xO9blEuFdlGsoKTpcZMuM1ZVvY1jNnzhQ2pUA+RWY4txaSzftUmnlNGKqsLXceBP52KUPng+/4xjSIB74xDeKBb0yDDFXjX3311UUF2E9+8pPFdurPcdLhJNeytdAQtSu1LkNi1LYMYzFkxjBWHopinw4axqL/gWFRbufxepXmos7mvmpprgxr8fssr5X3I5c6U5Pzt8e2MPTMa8Zrzn6tVeXt1bZ8Sfh88R3fmAbxwDemQTzwjWmQkS7LXcxYZ62sU013U2NRH1I//uQnP5l+Td3L71LfsS218sn8Pm32Yx6TZskwxquZS/HOO+8UNnU028pUVGr6vJ+4jeWveB6MnTOll9tr+RDr16+ffv32228X25gzQnhNuMz77Nmzhc1+WciyXPabl+UaY+aFB74xDeKBb0yDjHXpLeqiXMNR0zOHnDY1XG2ZJWPtzM3O9Sa1JXPKGXevlV6m/4H6ktq1Vy43z5NalP1C+7rrritsPhqKbemVJ8B21p60Sy1bW0dA/wVzCvLfEzU4cyXYVrZtz549hc1Sb7zmfMzZQnJUvCzXGDMvPPCNaRAPfGMaZKQan+vKqW1p57q99ngl6j2uS+d6a+a7M57dS2dTS/Kx1twXH5nFuHwe+5Zm+hAIy5DlMWr2Ya2EGH0dr732WmHT78L1/OyL/DrwmvG8eB7sR/pGXn/99cKu5Tfkvx/+PuhnoW9j27ZthU3fSc3vshiPtr4I/Qe5/4F+k7nwHd+YBqkO/Ij4dkRMRsT+7L3rI+LpiJjo/r2u1z6MMeNFP3f8RyXtxHsPS9qdUtoiaXfXNsZcIlQ1fkrp/0TEBrz9RUn3dV8/JulZSV8b9ODUVdRs1IurV6+efk3tSs1GDVYrvcz4NvfPOG4e76Z+q+VpM2ZMXwe1L/fPtlDL5nqTupoakNegppMZ56/VA8yPx8dMsR/oC6GdX//Z2sbcDvp1ch9Br7UX0szHYPP3wDUQ5NVXXy1s5iDQXzEIrLmXj5PampWLzFfjr0gpXfQgnZK0oteHjTHjxYKde6nzX8yc/81ExEMRsTci9vJ/cGPMaJjvwD8dEaskqft3cq4PppR2pZR2pJR21JY+GmOGw3zj+E9KekDS17t/n5jPTmrxa66/znUSa6a98cYbPffNfVHr0ifA7XxMdh6nPXHiRM9jM6Z78uTJwqZWpf6jbmOtOurHXI9SyzLPu1ZLgN/nuVDj0y+T5yzUfBebN28ubM4QuX6f51LzheQ2z4OandefdfPZTzzv2vaFwPPOz4X5BHPRTzjvbyX9m6StEXE8Ih5UZ8B/PiImJP27rm2MuUTox6v/lTk2fW6R22KMGRLO3DOmQUaaq0/dzcdic711HiPmc9KoNamzGa+mTe68887CZmw+z/umxmYsm3XQ2TbWvaOm5+cZU+4VI+a+arn23Bf9LrXHPdP3kvtOqD/5WebqM1++Vuue15Rr4PMaffws+6mWe0/4W+X++o2v9wP7LfdtMDdiLnzHN6ZBPPCNaRAPfGMaZKzq6rOeG/Pv83g5NRfrs1Hz0yfAfVPbch06/RF522v12Rh/ZoyY2pWJTowJc90BNX/eVsaPa8/toz+B/VrbH9uex7/p+6jVTGBuBbUt+515AsyvyPuNv73Dhw8XNp/r+PGPf7ywmWPAGv/0ESymxudvNT8v+hrmwnd8YxrEA9+YBhnpVL/2SGVO3fIpLKdSXFbLaWCt9DKnYpzCcpqZf57TPKaOcrrM6TTLgDG8xxRNngv7Ip/6cbrcKw1amilx2A+1KeyRI0cKO3+cNOUXQ4WcpjLUSGrhwV6lxPldyin+FpkSzt/PoGnXC4FSL7f7LdvtO74xDeKBb0yDeOAb0yBjFc7L9aA0Mz0013zUwdQ91DrU1dR41LJMH6bmy0tY81gMr3Hf9AEwNET/BPuplpaZ63pqS4bU2MfsF54bt7McFkOX+RJk+hOYcsu20pdRKxtGXwjbmof3ao8eJ7wGtcdesx/o31gI9H3k/gT+TufCd3xjGsQD35gG8cA3pkFGqvGpqw4ePFjY69evL+xcZ9UeK0VtSo1GnURdzZgwyUtKUe/xu0wXZnyZsG30CdCfwVJe+ffZNuYUMAeB/cRSztTd9E/U8iFyeP2pT2uPReOx2A8kj73Xyojz2PRlcDv9C7USZwuB1z+/pv2W+PId35gG8cA3pkE88I1pkJFqfGpXllpinnkeg6ZmYvlrPsKIupnlsOgTyEtrSTN1ea4vqU0ZK+9V5lmaGZ/msWrrCuhTyM+ttkaB/XD06NGeban5ALi0NvedsN30q3AZLUte89gs1cX8iVtvvbWw87g+fUT0RbAtNbjegr/txczV5zXttQx7LnzHN6ZBPPCNaRAPfGMaZKQan7qHOvvGG28s7FzTTUxMFNsOHDhQ2L0eHS3V153zMVUk11KM6fI8uG/mx9di5fw+144zZpyva+d5M65PbVp7/DPLo1EL33333YWdX+N8fcNsbWHZLrad/cwcBPpO3nzzzcLO+5nrQujboI+HfcxryNz8VatWFTZ9UvStDAL9B3m/8Xc/F77jG9MgHvjGNIgHvjENMlKNT2655ZbCpl7Ja7Rt2rSp2MaaaPQfMG5L/chjU2dzDXyef09tyfgyNTp1NeP4zMVmvJvxaurV3AfAnAL2C7XpunXrCpv9xu9T+9K/kZ8L8915zbZs2VLY7HP2I3U4dTTbltcDYFlx/h64L14j9uuaNWsKm/UD2Y8L0fiM1ee+MGt8Y8ycVAd+RKyLiGci4pWIOBARX+2+f31EPB0RE92/19X2ZYwZD/q5409J+sOU0jZJn5H0exGxTdLDknanlLZI2t21jTGXAFVBkFJ6W9Lb3dfnIuKgpDWSvijpvu7HHpP0rKSvDXLwWryba73zOC7j7KyRR43GY9Xi/lwn0CtWT38A46yMV3NNAvPba49jYlu4LiHXfLVcffYLa92zH6hN6W/gueTH53nU1vZTF9dqJvBcGJvPfSuMw9Omf4B9zn6gD4D90m8OfT/Qp5SPBfbpnPsY5IARsUHS3ZKek7Si+5+CJJ2S1DvjxRgzNvQ98CPiGkl/L+n3U0rFbSF1XL2zLj+KiIciYm9E7OX/6MaY0dDXwI+Iy9UZ9H+TUvqH7tunI2JVd/sqSZOzfTeltCultCOltIMpmcaY0VDV+NERTt+SdDCl9BfZpiclPSDp692/Tyy0MdT4XAue6yxqKMbGqQ+pVamFmP/e69hSGauvPV+OepE55LW4PX0E1LK9bJ4XtSx9G7VHUdMHQFjLLm8LY9/00/CaMhbO5/7xGvJcaOfXib+P22+/vbDZ58x3YO7Enj17Cpu/R67HWEzmE8fv51P3SvqPkl6OiBe67/2JOgP+uxHxoKRjkr48SGONMaOjH6/+v0qa6xGcn1vc5hhjhoEz94xpkKHn6ue53tSDjH8zNprrRWo05m1z34yjMp+ecDvbluf2c505a9fXavJR49NnwLbTScpzz/uN+6J2rdWG47F4rvRn8FxyHc5rwigPcy9Yj4HP3qPmpx+H/ohc/95xxx3FNl4T5lKQffv2FTb9E1x3wLYvJq6rb4zpCw98YxrEA9+YBhmqxp+amir0KOvm1fLKc61MjU8Nxfj15s2bZ7Qlh3F77o9rAV588cVZ2yXN1NFcV862UGfz84cPHy5s6nDWEshjyOwHfpdtpU7mvmu1CHs9Z575BrwGjEGzH7iGnjqd16HXmgm2k8837JWPMNu+6Y9gP3LdwL333ttz/4PgmnvGmL7wwDemQYY61V+2bFkxhWYpZqZoMsRy7Nix6ddc2sowEqfqDB3VUlO5P5bjzqd6nD5zisqQF6eBtRAbH/9Vs3s9QpxhSqaecvrN8lgMubGfee65zdJbLNXNkBhDidz3W2+9Vdj8/bAft27dOv2aj9TmVJvnyWvEfmLomWFUXqNaaflByNOBPdU3xsyJB74xDeKBb0yDDFXjR0Shu1j+irqKGjDXyix9xDRZhrGoH6nBqNFquj3XeNS5DO3Qf8DQIfUf28Lvr127trB7lQ1jGDL3k0gz/QFMg+W58Vi1FNFcf/IacLkyYYiN4V7a9F9Ql+dlwegPYCiQ8JFYXKbLY9dSvhei6Unu73LKrjFmTjzwjWkQD3xjGmSkj9DisslaqmuuX6iTuYySKZdMNaWu5rEZv6ZGy7UvfRNcJsvvUutSD1J3U8vyXLmd2jiH58l+4r7pO6npbpKX+mJcnv3C82aKLo9FXwhj68z1yH1GfFQYv8s4P30f1NL8DdBHxN8T29Zv/H02epVTnwvf8Y1pEA98YxrEA9+YBhm6xs/jlyxBzJx2xtrvvPPO6dfU/9RkzPPnvpmrT41HTce4K2P1OdSm1NXUgzw2qZXyok7Pz622RqG2ZqFWwpo6mzo9384+rJVA577pl2E/sF/pQ8jbzj7j76lWJowanz4nxvlZiquWNzAI+bqSfvMDfMc3pkE88I1pEA98YxpkpHF8rnmnRluzZk1h5zqKGovlrFiuitqHGqum8ajRcv154sSJYht18fr16wub2pO+DD7mivkOtTLTuW6nbmYfE/ojqOnZb1wTwVh9nqtPncw+rq15p0+gVvKMj+zOj0d/AX1A9HXUHs9FfwTj9MzV4PEWU/P3g+/4xjSIB74xDeKBb0yDjPQRWitXriy2UcNR2+bal/nufPQ0fQCMVzPOSp1MfcnYfO6foKZnnjZzDFhLgPqQWrim/1h7Ll87zj6ltmQfsy1ct87t7Gf2W66rqf+5LoD+Av4+ej0SS5rZ770ee8bPsk4B/U/sx9qxayXSWRq83xz7xcJ3fGMapDrwI+LKiPh+RLwYEQci4s+772+MiOci4khEfCcirqjtyxgzHvRzx39P0v0ppbskbZe0MyI+I+kbkr6ZUtos6YykB5eumcaYxaSq8VNHvFxMfL+8+y9Jul/S73Tff0zSn0n669r+co24f//+Yhtjq9R0eQyaufjUwYzb1+L4PBb1Jtdv599nzJb+BGp2xulpUzczV5/9RD2Z60/Wza/Fn1lLoLamoZb/kD9Wm7UCCXV17fHgbDtzFqjLc78O6/3RZr8dOnSosGtrHI4cOVLYt912W2HzXIdNXxo/IpZFxAuSJiU9Lek1SWdTShd/BcclrZnr+8aY8aKvgZ9SOp9S2i5praR7JN1W+co0EfFQROyNiL288xljRsNAXv2U0llJz0j6NUnLI+LivHGtpBNzfGdXSmlHSmkHp2rGmNFQ1fgRcZOk91NKZyPiKkmfV8ex94ykL0l6XNIDkp6o7evChQtFXvr27duL7YyF7tmzZ87ttRplmzZtKmzqP2os5vpzdpLnnEulvmSMllCjMzefOeasD0g9yXNhbD7PC+ezCZjnz5wCtoU6mrn+tevAevQ5zMWgv4DnyX5k7JvrKfj7yWPnvAb0GdE/wO21+oGE6znYr7wOS00/CTyrJD0WEcvUmSF8N6X0VES8IunxiPivkvZJ+tYSttMYs4j049V/SdLds7z/ujp63xhzieHMPWMaZKi5+ufPny/i4730nzRTR+VxXeZxs245a6BRH9Z8AIytM76d60vG1Rl/Zg4BY+Hcztr19H1Qn1K35+sWajUPuMaBaxbyOPxs+6Pvg/2e5zvU6uDX1tfXchD4fdZ0zNvGvA1eA2py/l6o6ScmJgqb6+/5m2C+w7DxHd+YBvHAN6ZBhj7Vz6dbtak+p3b59IzhFaZMMlTEqRmnhSzTxGkmp9P5VK3X8k9p5pJeTtUpFRjOq02JGe7Lp62UCVwKy+kyy4Zzas9+ZSiRU+b8OvVasivNvN6UJbW0a17D1atXFzbTsHsdi+fJfqIc4++Pn2c/8boMG9/xjWkQD3xjGsQD35gGGarGn5qamhEW6wV1Uq67qcFqy0fpE6CGp37kMk1qsjyls7acuJb2ylAPP8+2sS3s07xcFsNz1NEbN24sbPojmLpKLVtbppv7P9hu9gNDYAypsl8YomU5tddee23Oz/M8apqbbaHGry2zpcYfNb7jG9MgHvjGNIgHvjENMtYanxow15vUrizrxHg1tShTUanTa9o4Px73xTg9tSlzAhi3Z7lsUtPV+bkw1s22MGWX/VDT9PSF9Cq3XXvkNvfNz9PXUdPV9PvkUHPTZj/w2PRHbNu2rbBZeos5BPQ5DRvf8Y1pEA98YxrEA9+YBhm6xmestRfUi7kmZJml2qOkGfN99dVXC5uanu2k/sx1OXMKeCxqUersmqavlZmmjyFfKlt7ZBbXS/DzjFczns34d68y58wJoG+C/gL6F9gPtUdqcS1A3jZeT14jnuegS4Zr/oxR4zu+MQ3igW9Mg3jgG9MgQxUe77//flHumfqwtt461+2Mk9YeM8wcdOpFxm2pARmHzXU9892p53hezCGvxYiZF8B+YVtzLV0r88VrQI1P3c1yVizfzX7NdTo1N8+rpvF5LvTDMO+D+8/XDdA/QJvQF1J7RsT69et72uynYeM7vjEN4oFvTIN44BvTIEOP4+ePpqppfMa7T548Of2aj6bmZwl9ANRY1IO0SX4e1NzUptTFPDZzyqmFWcKa/gaWfs6/z7LhbCtzEHhNqKvpA+iVa8Hj0Y/Ca5LXEZBmxsp5Ljw22876gbldi+PT5m+zRs3nNGp8xzemQTzwjWkQD3xjGmToGj9fJ0+dRW3MfPt8zTPXkddqqLH2PbUq88a5P34+X4/P+DE/y7XX9Ef0yimfrS08N2rfXvXjuG9CLcuc9dqaeG7PdXrt2Qb0AXDNA2PhtfX6ixkrr/mjLjV8xzemQfoe+BGxLCL2RcRTXXtjRDwXEUci4jsRcUVtH8aY8WCQO/5XJR3M7G9I+mZKabOkM5IeXMyGGWOWjr40fkSslfQfJP03SX8QHYFzv6Tf6X7kMUl/Jumve+1namqqWN9NbUstS/2Y68U1a9b0/Cz3TR1ce4wxY8DUeLn+pA5mDjnzwJnbT/8C6wUyvk0fQa+1AVwDT13N8+5Vv0+amXPAfuy1Dp39xLbV8t9HyaWu6Um/d/y/lPTHki7+4m6QdDaldNE7d1zSmtm+aIwZP6oDPyJ+U9JkSun5+RwgIh6KiL0RsZd3YWPMaOhnqn+vpN+KiC9IulLSRyT9laTlEXFZ966/VtKJ2b6cUtolaZckXXvttaN9NrAxRlIfAz+l9IikRyQpIu6T9Ecppd+NiL+T9CVJj0t6QNITtX2dP39eZ8+enbYHnQHkNfm5PpoajHqR68YJtWreTmmmHs21bK2OPtvGttB/wGPT98F1Cvx+rsup0ekLoX+A+fGMpdfyAHpB/8G4PU+uJRYSx/+aOo6+I+po/m8tTpOMMUvNQJl7KaVnJT3bff26pHsWv0nGmKVmqCm758+fL0JbDO9w+SmnyFu3bp1+zaWpTOGthV8YxuIUl9N1fr5XSWxO/RniqtlMAWYIjdNvnusgoSdOvw8cOFDYd911V2GzDPkgcGrPa3jzzTcX9kJkhemNe9aYBvHAN6ZBPPCNaZChavwLFy4US1Sp8WvkqawMeVE/1sJUhCExhhpXrlxZ2Lkup+6lRmdb6C/gsSYmJgqbjwBfiPal7+Kll14qbJYJW8xUVfYDfSFvvPFGYW/YsKGwB11my2uan/uoy1uPGt/xjWkQD3xjGsQD35gGGbrGz7U2S1LVyDUbNT11L7Uq01wZC6/F0odZLpkpuoups6l72S9MhWbK70LgeTCOz7ToWi7FoMdrXdfn+I5vTIN44BvTIB74xjTI0DV+nhteezQxyeO6jPH2enTTuEP/AbUt8+npfxgE9gtLXjNXn/3MkmSD6GaeJ/Mf2BazdFw6o8MYs2h44BvTIB74xjTIUDV+SqnIS2cctwbj278qMN7MeDZz2hei8Xks5lLwmrAsOXU6ayj0gjkEPE+WP2Ouxrg/evpSwnd8YxrEA9+YBvHAN6ZBhq7x80djUz+aDozb83Hiiwlz8wlrJrDW4CAanzkE/O67775b2KxTwNLgZv74jm9Mg3jgG9MgHvjGNMhQNb5UxmbzR2KZ/w/XwC/luoPao8J4bPplGJvvVTuAmp35CYzjnz59urD5fIFW4VqO3Ob1mAvf8Y1pEA98YxrEA9+YBhm6xs/J6+S3DHXZ5ORkYXPdOusJLgTqbD5/gOvtly9fXtiDaHxq+FtvvbVn2y7lx2hThzMXg/2a+1J6PQ9gtu396vrieAN/wxhzydPXHT8ijko6J+m8pKmU0o6IuF7SdyRtkHRU0pdTSmeWppnGmMVkkDv+r6eUtqeUdnTthyXtTiltkbS7axtjLgEWovG/KOm+7uvHJD0r6WuD7IBxfGqZS6lu3kKgLl7MZ+XVWL16dWHzGYHXXHNNYVObDlLzn59lnURS274QajqZfT7ob7O2nf6LvF9rNReZe3Hq1Knp17VnRE63r69PSUnSv0TE8xHxUPe9FSmlty8eW9KK2b4YEQ9FxN6I2NvnsYwxS0y//6V+NqV0IiJulvR0RLyab0wppYiY1bWYUtolaZckzfUZY8xw6euOn1I60f07KekfJd0j6XRErJKk7t/JufdgjBknqnf8iLha0gdSSue6r39D0n+R9KSkByR9vfv3iUEPfuZMGQSoPQ9vIQwSbx42bAufZ0fNt5hcSvnvtX5g7QDW6Mtt9nnt91CLlbNtrGXINQ7Hjx8v7MOHD0+/fuGFF4ptr7zySmGzJkKeD9NvHct+pvorJP1jt2Muk/Q/Ukr/MyL2SPpuRDwo6ZikL/d1RGPMyKkO/JTS65LumuX9H0r63FI0yhiztIw0Zbe2JJRTtVwKLPSRyeMEp5E33XTTiFqycCjXcpvXc9BrUpvqMyW41/65L5b9eueddwr7zTffLOx8ai5JL730UmHv37+/sI8dO1bYnPrnxx9GqnIbgXJjTIEHvjEN4oFvTIOMVOMz9MAloixBlacjDqLnxp1xbnutFFct5Jqf22KfZ02XU1cfPHhw+jU1+aFDhwqbmp5LyBk6XMqQ61LgO74xDeKBb0yDeOAb0yAj1fhMa+Tyw16acJxTcJeaWmmmnEHzHQiXxtb6mcfL28oUbZYYO3r0aGEzVfXll18ubOpypsFy2XfuI7rUNPli4zu+MQ3igW9Mg3jgG9MgI9X4jIXWygaxDNSvKoydk146Wlrc5czU9OfOnSvsiYmJwt63b19hP//889OvDxw4UGxjnJ1xeP4e5lNG2syO7/jGNIgHvjEN4oFvTIPEMHVTRLyjTrWeGyWN6/OzxrVt49ouyW2bL0vRtvUppWpBh6EO/OmDRuzNHswxVoxr28a1XZLbNl9G2TZP9Y1pEA98YxpkVAN/14iO2w/j2rZxbZfkts2XkbVtJBrfGDNaPNU3pkGGOvAjYmdEHIqIIxEx0sdqR8S3I2IyIvZn710fEU9HxET373W99rGEbVsXEc9ExCsRcSAivjou7YuIKyPi+xHxYrdtf96aJnbCAAAC5klEQVR9f2NEPNe9tt+JiCuG3bZuO5ZFxL6IeGrM2nU0Il6OiBcuPkB2lNdzaAM/IpZJ+u+S/r2kbZK+EhHbhnX8WXhU0k6897Ck3SmlLZJ2d+1RMCXpD1NK2yR9RtLvdftqHNr3nqT7U0p3SdouaWdEfEbSNyR9M6W0WdIZSQ+OoG2S9FVJBzN7XNolSb+eUtqehfBGdz1TSkP5J+nXJP1zZj8i6ZFhHX+ONm2QtD+zD0la1X29StKhUbYva9cTkj4/bu2T9CFJ/1fSp9VJRLlstms9xPasVWcA3S/pKUkxDu3qHvuopBvx3siu5zCn+msk5U/7O959b5xYkVJ6u/v6lDrPDRwpEbFB0t2SntOYtK87nX5BnSckPy3pNUlnU0pT3Y+M6tr+paQ/lnSxvM4NY9IuSUqS/iUino+Ih7rvjex6jnRZ7jiTUkoRMdKQR0RcI+nvJf1+Sukn+RLZUbYvpXRe0vaIWK7OY9NvG0U7ciLiNyVNppSej4j7Rt2eWfhsSulERNws6emIeDXfOOzrOcw7/glJ6zJ7bfe9ceJ0RKySpO7fycrnl4yIuFydQf83KaV/GLf2SVJK6aykZ9SZQi+PiIs3klFc23sl/VZEHJX0uDrT/b8ag3ZJklJKJ7p/J9X5z/IejfB6DnPg75G0petlvULSb0t6cojH74cnJT3Qff2AOtp66ETn1v4tSQdTSn+RbRp5+yLipu6dXhFxlTq+h4Pq/AfwpVG1LaX0SEppbUppgzq/rf+dUvrdUbdLkiLi6oj48MXXkn5D0n6N8noO2cHxBUmH1dGEfzoKJ0vWlr+V9Lak99XRfg+qowl3S5qQ9L8kXT+itn1WHU34kqQXuv++MA7tk/RxSfu6bdsv6T93398k6fuSjkj6O0kfHOG1vU/SU+PSrm4bXuz+O3Dxtz/K6+nMPWMaxJl7xjSIB74xDeKBb0yDeOAb0yAe+MY0iAe+MQ3igW9Mg3jgG9Mg/w/7RyVlP8J7NwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================================\n",
    "# Check your data to make sure it is correct\n",
    "# ========================================\n",
    "\n",
    "for data in book_data_loaders['Defoe']['train']:\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "\n",
    "    # plot to verify the input is correct\n",
    "    input1 = inputs[0].numpy()\n",
    "    print(input1.shape)\n",
    "    input1 = np.swapaxes(input1,0,2).squeeze()\n",
    "    print(input1.shape)\n",
    "    plt.imshow(input1,cmap='gray')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pretrained mnist model\n",
      "Building and initializing mnist parameters\n",
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=784, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.2)\n",
      "    (5): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2)\n",
      "    (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Step 3. define model structure\n",
    "#\n",
    "# TODO: Stick with MNIST for now because it is smaller network and faster to train. Note that you lose\n",
    "# a lot of inofmration when yo udownsample the image to 28x28. THat's okay, you optimize other parts first, e.g.,\n",
    "# data loading before you optimize your model.\n",
    "# ========================================\n",
    "from lib.playground.utee import selector\n",
    "from lib.playground.mnist import model\n",
    "import os\n",
    "\n",
    "def create_model_architecture(model_type='mnist'):\n",
    "    \"\"\"\n",
    "    params model_type: the type of model, for now, support mnist and resnet18    \n",
    "    \"\"\"\n",
    "    if model_type == 'mnist':\n",
    "        print('using pretrained mnist model')\n",
    "        \n",
    "        # load the model from the playground library\n",
    "        model_annotation, ds_fetcher, is_imagenet = selector.select('mnist')\n",
    "        \n",
    "        # remove last layer\n",
    "        removed = list(model_annotation.model.children())[:-1]\n",
    "        \n",
    "        # add a front layer to account for new input\n",
    "        # IMPORTANT, we need to update the self.input_dims of the MLP class\n",
    "        removed = [nn.Linear(img_input_size*img_input_size,28*28), nn.ReLU()] + removed\n",
    "        \n",
    "        # formulate the layers\n",
    "        model_annotation.model=torch.nn.Sequential(*removed)\n",
    "        \n",
    "        # add the new fc layer\n",
    "        model_annotation.model.fc = torch.nn.Linear(256,2).cuda()\n",
    "        \n",
    "        # update the self.input_dims of the network\n",
    "        model_annotation.input_dims = img_input_size * img_input_size                \n",
    "\n",
    "    elif model_type == 'resnet18':    \n",
    "        print(\"Transferring resnet18 and retraining with annotations dataset.\")    \n",
    "        model_annotation = models.resnet18(pretrained=True)\n",
    "        num_params = sum(1 for i in model_annotation.parameters())\n",
    "\n",
    "        # There are 10 layers (model_ft.children()) in resnet18\n",
    "        # Freezing the first half of resnet18, freezing all params for layers 1-5\n",
    "        max_layer = 5\n",
    "        curr_layer = 1\n",
    "        last_layer = None\n",
    "        for child in model_annotation.children():\n",
    "            if curr_layer <= max_layer:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "                last_layer = child\n",
    "                curr_layer = curr_layer + 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Replace the final fully connected layer to perform binary classification\n",
    "        num_ftrs = model_annotation.fc.in_features\n",
    "        model_annotation.fc = nn.Linear(num_ftrs, 2)\n",
    "        \n",
    "\n",
    "    # return\n",
    "    if use_gpu:\n",
    "        return model_annotation.cuda()\n",
    "    else:\n",
    "        return model_annotation.cpu()\n",
    "\n",
    "    \n",
    "net = create_model_architecture(model_type='mnist')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Step 4. define the training process.\n",
    "#\n",
    "# TODO: The basic process of train and validation is defined. Please implement the overall average validation \n",
    "# confusion matrix, meaning for each validation (after running all epochs), get the confusion matrix for that book,\n",
    "# repeat this for the rest of 10 books. THen get the overall performance. Also, implement the early-stop as you\n",
    "# originally has in your code. :) I removed them here for clarity. You can add them back. \n",
    "# ========================================\n",
    "\n",
    "def train(model, criterion, optimizer, data_loaders, num_epochs=25, early_stopping = None):\n",
    "\n",
    "    # stop the training, validation, and test loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # looping parameters\n",
    "        running_loss = 0.0\n",
    "        confusion_matrix = tnt.meter.ConfusionMeter(2)\n",
    "        \n",
    "        # loop through train and val phase in each epoch\n",
    "        for phase in ['train', 'val']:\n",
    "            # check train or val\n",
    "            if phase == 'train':                \n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            # Iterate over each book\n",
    "            running_loss = 0.0\n",
    "            confusion_matrix = tnt.meter.ConfusionMeter(2)\n",
    "            for book in tqdm_notebook(data_loaders[phase]):\n",
    "                for data in data_loaders[phase][book]:\n",
    "                    # get the inputs;  wrap them in Variable and make them into gpu or not\n",
    "                    inputs, labels = data # input size: [5, 1, 28, 28] ; keep the dummy color channel:1\n",
    "                    if use_gpu:\n",
    "                        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                    else:\n",
    "                        inputs, labels = Variable(inputs), Variable(labels)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # back\n",
    "                    if phase == 'train': \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # Add to confusion matrix\n",
    "                    confusion_matrix.add(outputs.data, labels.data)\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.data[0] * inputs.size(0) \n",
    "            \n",
    "            # report evaluation\n",
    "            print('Phase:%s' %phase)\n",
    "            print('Confusion matrix:\\n', confusion_matrix.conf)\n",
    "            print('validation loss', running_loss)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pretrained mnist model\n",
      "Building and initializing mnist parameters\n",
      "Epoch 0/0\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878c356589ee4510a7b3927741e92d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:58: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase:train\n",
      "Confusion matrix:\n",
      " [[  81  537]\n",
      " [ 172 1854]]\n",
      "validation loss tensor(1692.0262, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302557a4f21a42b59d91ef6f4a951543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase:val\n",
      "Confusion matrix:\n",
      " [[  0 143]\n",
      " [  0  31]]\n",
      "validation loss tensor(236.1483, device='cuda:0')\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Step 5. execute the train process\n",
    "# ========================================\n",
    "\n",
    "# get the model\n",
    "model = create_model_architecture()\n",
    "\n",
    "# train parameters\n",
    "num_training_epochs = 1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "earlyStoppingCriteria = EarlyStopping(min_delta = 1e-4, patience=5)\n",
    "\n",
    "# dataloader parameters\n",
    "cross_val_loaders = {}\n",
    "\n",
    "# leave-one-book-out cross validation\n",
    "for val_book in books_in_data:\n",
    "    \n",
    "    # define the train and validation loaders\n",
    "    train_books = books_in_data - set([val_book])    \n",
    "    cross_val_loaders[\"train\"] = {b : book_data_loaders[b][\"train\"] for b in train_books}\n",
    "    cross_val_loaders[\"val\"] = {b : book_data_loaders[b][\"val\"] for b in [val_book]}\n",
    "\n",
    "    # train\n",
    "    trained_model = train(model,\n",
    "                          criterion,\n",
    "                          optimizer,\n",
    "                          cross_val_loaders,\n",
    "                          num_epochs=num_training_epochs)\n",
    "    \n",
    "    # remove the break as needed\n",
    "    break\n",
    "\n",
    "print(\"training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mnist.pth'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('', 'mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
